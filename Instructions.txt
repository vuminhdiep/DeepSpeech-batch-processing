#Activate virtual environment
source $HOME/tmp/deepspeech-gpu-venv/bin/activate

#Run convert_48khz_to_16_khz.py to convert ./audio/raw_audio to ./audio/ATL, etc.
python convert_48khz_to_16khz.py

#Run data_preprocess.py to add the Flag "Good", "Bad" to from og_refer_text/ATL to have ./transcript/raw_refer_text/ATL
python data_preprocess.py

#Run driver.py for batch processing, change ATL to according subset
./driver.py --model ./models/deepspeech-0.9.3-models.pbmm  --scorer ./models/deepspeech-0.9.3-models.scorer --dirname ./audio/VLD/ 

#Run json_to_txt.py to convert transcribed json and saved to ./transcript/ATL/hypo_text, remember to change subfolder name ATL to according subset
python json_to_txt.py

#Run preprocess_reference.py to change ./transcript/raw_refer_text/ATL/ to ./transcript/refer_text/ATL to calculate WER
python preprocess_reference.py

#Run wer_calc.py to calculate WER for a subset, change {sub-dialect-name} to ATL, DCA, etc.
python wer_calc.py >wer_record_{sub-dialect-name}.txt

==============================================
#Segmentation for training DS

#Run algo.py
python algo.py

#Run text_segment.py, change sub-dialect folder
python text_segment.py

#Run audio_segment.py, change sub-dialect folder
python audio_segment.py

#Run convert_to_csv.py
python convert_to_csv.py

